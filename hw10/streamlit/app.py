# hw10/streamlit/app.py
import os, sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import streamlit as st
import numpy as np
import faiss
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer, CrossEncoder
from sklearn.preprocessing import normalize

from utils import load_data, generate_embeddings, hybrid_search_with_rerank

st.set_page_config(page_title="ĞšĞ½Ğ¸Ğ¶ĞºĞ¾Ğ²Ğ° Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ", layout="wide")
st.title("ğŸ“š ĞšĞ½Ğ¸Ğ¶ĞºĞ¾Ğ²Ğ¸Ğ¹ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ‚Ğ¾Ñ€")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ĞœĞ¾Ğ´ĞµĞ»Ñ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def load_models():
    st.info("â¬‡ï¸ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ”Ğ¼Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ–â€¦")
    embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L12-v2")
    reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
    return embedder, reranker


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ğ†Ğ½Ğ´ĞµĞºÑ + BM25 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def prepare_index(df, _embedder):        # ğŸ‘ˆ Ğ¿Ñ–Ğ´ĞºÑ€ĞµÑĞ»ĞµĞ½Ğ½Ñ
    corpus = df["description"].astype(str).tolist()
    tokenized = [t.split() for t in corpus]

    bm25 = BM25Okapi(tokenized)

    emb = _embedder.encode(              # ğŸ‘ˆ Ğ½Ğ°Ğ·Ğ²Ğ° Ğ·Ğ¼Ñ–Ğ½Ğ½Ğ¾Ñ— Ñ‚ĞµĞ¶ Ğ· Ğ¿Ñ–Ğ´ĞºÑ€ĞµÑĞ»ĞµĞ½Ğ½ÑĞ¼
        corpus, convert_to_numpy=True, show_progress_bar=True
    )
    emb = normalize(emb)

    index = faiss.IndexFlatIP(emb.shape[1])
    index.add(emb)
    return index, bm25, emb


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "ukr_books_dataset.csv"))
df_books = load_data(DATA_PATH)

embedder, cross_enc = load_models()
faiss_index, bm25_model, doc_emb = prepare_index(df_books, embedder)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ĞĞ¿Ğ¸ÑˆÑ–Ñ‚ÑŒ ĞºĞ½Ğ¸Ğ³Ñƒ Ğ°Ğ±Ğ¾ Ğ¶Ğ°Ğ½Ñ€")
query = st.text_input(
    "Ğ”Ğ¾Ğ±Ñ€Ğ¾Ğ³Ğ¾ Ğ´Ğ½Ñ! ĞĞ¿Ğ¸ÑˆÑ–Ñ‚ÑŒ ĞºĞ½Ğ¸Ğ³Ñƒ Ñ‡Ğ¸ Ğ¶Ğ°Ğ½Ñ€, ÑĞºĞ¸Ğ¹ ÑˆÑƒĞºĞ°Ñ”Ñ‚Ğµ:",
    placeholder="ĞĞ°Ğ¿Ñ€. Ğ¿ÑĞ¸Ñ…Ğ¾Ğ»Ğ¾Ğ³Ñ–Ñ‡Ğ½Ğ¸Ğ¹ Ñ‚Ñ€Ğ¸Ğ»ĞµÑ€ Ğ¿Ñ€Ğ¾ Ğ¾ÑĞ¾Ğ±Ğ¸ÑÑ‚Ñ–ÑĞ½Ğ¸Ğ¹ Ñ€Ğ¾Ğ·Ğ²Ğ¸Ñ‚Ğ¾Ğºâ€¦",
)
k = st.slider("Ğ¡ĞºÑ–Ğ»ÑŒĞºĞ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ğ¹ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚Ğ¸?", 1, 20, 5)

if st.button("ğŸ” Ğ—Ğ½Ğ°Ğ¹Ñ‚Ğ¸ ĞºĞ½Ğ¸Ğ³Ğ¸") and query:
    with st.spinner("ĞŸĞ¾ÑˆÑƒĞºâ€¦"):
        results = hybrid_search_with_rerank(
            query=query,
            bm25_model=bm25_model,
            faiss_index=faiss_index,
            embeddings=doc_emb,
            texts=df_books["combined_text"].tolist(),
            df=df_books,
            cross_encoder=cross_enc,
            top_k=k,
        )

    st.success(f"Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(results)} Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ğ¹:")
    for rank, (row_id, score) in enumerate(results, 1):
        row = df_books.iloc[row_id]
        st.markdown(f"**{rank}. {row['title']}**")
        st.markdown(f"_Ğ–Ğ°Ğ½Ñ€:_ {row.get('genre', 'Ğ½ĞµĞ²Ñ–Ğ´Ğ¾Ğ¼Ğ¾')}")
        st.markdown(f"_Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³:_ {row.get('rating', 'â€”')}")
        st.markdown(f"_ĞĞ¿Ğ¸Ñ:_ {row['description']}")
        st.markdown("---")
